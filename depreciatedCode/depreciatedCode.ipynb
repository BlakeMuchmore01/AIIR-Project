{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay Buffer class for storing and retrieving sampled experiences\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, env, mem_size=MEM_SIZE):\n",
    "        # Initialising memory count and creating arrays to store experiences\n",
    "        self.mem_count = 0\n",
    "        self.states = np.zeros((MEM_SIZE, *env.observation_space.shape),dtype=np.float32)\n",
    "        self.actions = np.zeros(MEM_SIZE, dtype=np.int64)\n",
    "        self.rewards = np.zeros(MEM_SIZE, dtype=np.float32)\n",
    "        self.states_ = np.zeros((MEM_SIZE, *env.observation_space.shape),dtype=np.float32)\n",
    "        self.dones = np.zeros(MEM_SIZE, dtype=np.bool)\n",
    "\n",
    "    def add(self, state, action, reward, state_, done):\n",
    "        # If memory count is at max size, overwrite previous values\n",
    "        if self.mem_count < MEM_SIZE:\n",
    "            mem_index = self.mem_count\n",
    "        else:\n",
    "            # Avoiding catastrophic forgetting - retrain initial 10% of the replay buffer\n",
    "            mem_index = int(self.mem_count % ((1-MEM_RETAIN) * MEM_SIZE) + (MEM_RETAIN * MEM_SIZE))\n",
    "\n",
    "        self.states[mem_index]  = state     # Storing the state\n",
    "        self.actions[mem_index] = action    # Storing the action\n",
    "        self.rewards[mem_index] = reward    # Storing the reward\n",
    "        self.states_[mem_index] = state_    # Storing the next state\n",
    "        self.dones[mem_index] =  1 - done   # Storing the done flag\n",
    "        self.mem_count += 1                 # Incrementing memory count\n",
    "    \n",
    "    def sample(self):\n",
    "        # Randomly sample a batch of experiences\n",
    "        MEM_MAX = min(self.mem_count, MEM_SIZE)\n",
    "        batch_indices = np.random.choice(MEM_MAX, BATCH_SIZE, replace=True)\n",
    "\n",
    "        states  = self.states[batch_indices]    # Getting the states\n",
    "        actions = self.actions[batch_indices]   # Getting the actions\n",
    "        rewards = self.rewards[batch_indices]   # Getting the rewards\n",
    "        states_ = self.states_[batch_indices]   # Getting the next states\n",
    "        dones   = self.dones[batch_indices]     # Getting the done flags\n",
    "\n",
    "        # Returning the random sampled experiences\n",
    "        return states, actions, rewards, states_, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay Buffer class for storing and retrieving sampled experiences\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, env, mem_size=MEM_SIZE):\n",
    "        # Initialising memory count and creating arrays to store experiences\n",
    "        self.memory = deque(maxlen=mem_size)\n",
    "        self.mem_count = 0\n",
    "\n",
    "    def add(self, state, action, reward, state_, done):\n",
    "        # Adding experience to memory\n",
    "        self.memory.append((state, action, reward, state_, done))\n",
    "        self.mem_count += 1\n",
    "\n",
    "    def sample(self):\n",
    "        # Randomly sample a batch of experiences\n",
    "        batch_size = min(BATCH_SIZE, self.mem_count)\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        states, actions, rewards, states_, dones = zip(*batch)\n",
    "        return np.array(states), np.array(actions), np.array(rewards), np.array(states_), np.array(dones)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.mem_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining convolutional layers\n",
    "# Convolutional Neural Network (CNN) used for image inputs\n",
    "self.conv_layers = torch.nn.Sequential(\n",
    "        nn.Conv2d(self.input_shape[0], 32, kernel_size=8, stride=4),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "        nn.ReLU(),\n",
    ")\n",
    "\n",
    "# Getting the output size of the convolutional layers\n",
    "conv_out_size = self._get_conv_out(self.input_shape)\n",
    "\n",
    "# Defining the linear layers\n",
    "self.layers = torch.nn.Sequential(\n",
    "        self.conv_layers,\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(conv_out_size, FC1_DIMS),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(FC1_DIMS, FC2_DIMS),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(FC2_DIMS, self.action_space)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
